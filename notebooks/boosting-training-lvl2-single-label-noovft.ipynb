{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import statistics\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "import kaggle_toolbox.features.generation as features\n",
    "import kaggle_toolbox.nlp.features as text_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, EFeaturesSelectionAlgorithm\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from kaggle_toolbox.environment import Environment\n",
    "from kaggle_toolbox.features.transform import contiguous_to_categorical\n",
    "from kaggle_toolbox.path import format_path\n",
    "from kaggle_toolbox.prediction import PredDict\n",
    "from kaggle_toolbox.progress import NotebookProgressBar\n",
    "from kaggle_toolbox.trainer import train_kfold_model\n",
    "from kaggle_toolbox.typing import ensure_list\n",
    "from kaggle_toolbox.validation import analyze_val_strategy, build_fold_result_df\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from textstat import textstat\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LIST = [\n",
    "    'cohesion',\n",
    "    'syntax',\n",
    "    'vocabulary',\n",
    "    'phraseology',\n",
    "    'grammar',\n",
    "    'conventions',\n",
    "]\n",
    "TARGET = TARGET_LIST[0]\n",
    "\n",
    "SEED = 42\n",
    "NUM_FOLDS = 5\n",
    "FOLD_LIST = [0, 1, 2, 3, 4]\n",
    "\n",
    "ENVIRONMENT = os.getenv('__KGLTBX_ENVIRONMENT', 'laptop')\n",
    "_env = Environment(ENVIRONMENT)\n",
    "\n",
    "ROOT_DIR = _env.param(\n",
    "    kaggle=Path('/kaggle'),\n",
    "    colab=Path('/content/drive/MyDrive'),\n",
    "    laptop=Path('/kaggle'))\n",
    "DATA_DIR = _env.param(\n",
    "    kaggle=ROOT_DIR / 'input',\n",
    "    colab=ROOT_DIR / 'data',\n",
    "    laptop=ROOT_DIR / 'data')\n",
    "FP_ELL_DATASET_DIR = _env.param(\n",
    "    kaggle=DATA_DIR / 'feedback-prize-english-language-learning',\n",
    "    colab=DATA_DIR / 'fp-ell',\n",
    "    laptop=DATA_DIR / 'fp-ell')\n",
    "MODEL_DIR = _env.param(\n",
    "    kaggle=ROOT_DIR / 'working',\n",
    "    colab=ROOT_DIR / 'models/fp-ell',\n",
    "    laptop=ROOT_DIR / 'models')\n",
    "OOF_DIR = _env.param(\n",
    "    kaggle=ROOT_DIR / 'working',\n",
    "    colab=ROOT_DIR / 'oof/fp-ell',\n",
    "    laptop=ROOT_DIR / 'oof')\n",
    "\n",
    "TARGET_TO_LVL1_OOF_PATH_DICT = {\n",
    "    'cohesion': OOF_DIR / 'cohesion-v1-layer_norm-ep_4-valfreq_0p25-pooler_att-full.csv',\n",
    "    'syntax': OOF_DIR / 'syntax-v1-layer_norm-ep_3-valfreq_0p25-full.csv',\n",
    "    'vocabulary': OOF_DIR / 'vocabulary-v1-layer_norm-ep_3-valfreq_0p25-std_init.csv',\n",
    "    'phraseology': OOF_DIR / 'phraseology-v1-layer_norm-ep_3-valfreq_0p25-std_init-full.csv',\n",
    "    'grammar': OOF_DIR / 'grammar-v1-lnorm-ep_4-valfreq_0p25-sqzr_cat_9_to_12-full.csv',\n",
    "    'conventions': OOF_DIR / 'conventions-v1-layer_norm-ep_3-valfreq_0p25-full.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LVL1_SCORE_FEATURE_LIST = [f'{target}_lvl1_score' for target in TARGET_LIST]\n",
    "_FEATURE_GENERATOR_LIST = [\n",
    "    # Score-based\n",
    "    *features.L1Distance.pairwise_from_feature_list(_LVL1_SCORE_FEATURE_LIST),\n",
    "    features.Mean(name='lvl1_mean', feature_list=_LVL1_SCORE_FEATURE_LIST),\n",
    "    features.Stdev(name='lvl1_std', feature_list=_LVL1_SCORE_FEATURE_LIST),\n",
    "    # Custom simple\n",
    "    text_features.SubstrCount(name='num_commas', substr=','),\n",
    "    text_features.SubstrCount(name='num_dots', substr='.'),\n",
    "    text_features.SubstrCount(name='num_colons', substr=':'),\n",
    "    text_features.SubstrCount(name='num_semicolons', substr=';'),\n",
    "    text_features.SubstrCount(name='num_ellipsis', substr='...'),\n",
    "    text_features.SubstrCount(name='num_newlines', substr='\\n'),\n",
    "    text_features.SubstrCount(name='num_spaces', substr=' '),\n",
    "    # TextStat simple\n",
    "    text_features.Func(name='syllable_count', func=textstat.syllable_count),\n",
    "    text_features.Func(name='lexicon_count', func=functools.partial(textstat.lexicon_count, removepunct=True)),\n",
    "    text_features.Func(name='char_count', func=functools.partial(textstat.char_count, ignore_spaces=True)),\n",
    "    text_features.Func(name='letter_count', func=functools.partial(textstat.letter_count, ignore_spaces=True)),\n",
    "    text_features.Func(name='polysyllabcount', func=functools.partial(textstat.polysyllabcount)),\n",
    "    text_features.Func(name='monosyllabcount', func=functools.partial(textstat.monosyllabcount)),\n",
    "    # Custom complex\n",
    "    features.Div(name='ratio_commas', lhs_feature='num_commas', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_dots', lhs_feature='num_dots', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_colons', lhs_feature='num_colons', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_semicolons', lhs_feature='num_semicolons', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_ellipsis', lhs_feature='num_ellipsis', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_newlines', lhs_feature='num_newlines', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_spaces', lhs_feature='num_spaces', rhs_feature='char_count'),\n",
    "    # TextStat complex\n",
    "    text_features.Func(name='flesch_reading_ease', func=textstat.flesch_reading_ease),\n",
    "    text_features.Func(name='flesch_kincaid_grade', func=textstat.flesch_kincaid_grade),\n",
    "    text_features.Func(name='gunning_fog', func=textstat.gunning_fog),\n",
    "    text_features.Func(name='smog_index', func=textstat.smog_index),\n",
    "    text_features.Func(name='automated_readability_index', func=textstat.automated_readability_index),\n",
    "    text_features.Func(name='coleman_liau_index', func=textstat.coleman_liau_index),\n",
    "    text_features.Func(name='linsear_write_formula', func=textstat.linsear_write_formula),\n",
    "    text_features.Func(name='dale_chall_readability_score', func=textstat.dale_chall_readability_score),\n",
    "    text_features.Func(name='text_standard', func=functools.partial(textstat.text_standard, float_output=True)),  # type: ignore\n",
    "    text_features.Func(name='spache_readability', func=textstat.spache_readability),\n",
    "    text_features.Func(name='mcalpine_eflaw', func=textstat.mcalpine_eflaw),\n",
    "    text_features.Func(name='reading_time', func=functools.partial(textstat.reading_time, ms_per_char=14.69)),\n",
    "]\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    text_srs = df['full_text']\n",
    "\n",
    "    feature_arr_dict = text_features.generate_text_features(\n",
    "        generator_list=_FEATURE_GENERATOR_LIST,\n",
    "        text_seq=text_srs.tolist(),\n",
    "        progress_bar=NotebookProgressBar(),\n",
    "        init_feature_array_dict={\n",
    "            f'{target}_lvl1_score': df[f'{target}_lvl1_score'].values\n",
    "            for target in TARGET_LIST\n",
    "        })  # type: ignore\n",
    "    for feature_name, feature_arr in feature_arr_dict.items():\n",
    "        df[feature_name] = feature_arr\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_data(\n",
    "        dataset_dir_path: Path,\n",
    "        target_list: t.List[str],\n",
    "        target_to_lvl1_oof_path_dict: t.Dict[str, Path],\n",
    "        num_folds: int,\n",
    "        seed: int) -> pd.DataFrame:\n",
    "    all_df = pd.read_csv(dataset_dir_path / 'train.csv')\n",
    "    target_arr = contiguous_to_categorical(all_df[target_list].values)\n",
    "\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    for fold_, (_, v_) in enumerate(mskf.split(X=all_df, y=target_arr)):\n",
    "        all_df.loc[v_, 'fold'] = fold_\n",
    "\n",
    "    for target in target_list:\n",
    "        all_df = all_df.merge(\n",
    "            pd.read_csv(target_to_lvl1_oof_path_dict[target])\n",
    "                .rename({\n",
    "                    'id': 'text_id',\n",
    "                    f'{target}_score': f'{target}_lvl1_score',\n",
    "                }, axis=1),\n",
    "            left_on='text_id',\n",
    "            right_on='text_id')\n",
    "\n",
    "    all_df = build_features(all_df)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "all_df = _read_data(\n",
    "    dataset_dir_path=FP_ELL_DATASET_DIR,\n",
    "    target_list=TARGET_LIST,\n",
    "    target_to_lvl1_oof_path_dict=TARGET_TO_LVL1_OOF_PATH_DICT,\n",
    "    num_folds=NUM_FOLDS,\n",
    "    seed=SEED)\n",
    "\n",
    "analyze_val_strategy(all_df, target_list=TARGET_LIST, num_folds=NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(\n",
    "        train_model_fn: t.Callable[[t.Dict[str, t.Any], int], t.Tuple[float, PredDict]],\n",
    "        param_plan: t.Dict[str, t.List[t.Any]],\n",
    "        fold_list: t.List[int],\n",
    "        print_best_params: bool = False) -> t.Tuple[t.Dict[str, t.Any], t.List[float], PredDict]:\n",
    "    param_name_list = list(param_plan.keys())\n",
    "    param_comb_list = list(itertools.product(*[param_plan[param_name] for param_name in param_name_list]))\n",
    "    best_param_dict, best_score_list, best_pred_dict = None, None, None\n",
    "    it = tqdm(param_comb_list)\n",
    "    for param_value_tuple in it:\n",
    "        param_value_list = list(param_value_tuple)\n",
    "        param_dict = dict(zip(param_name_list, param_value_list))\n",
    "        param_str = ', '.join([f'{k} = {v}' for k, v in param_dict.items()])\n",
    "        if best_score_list is not None:\n",
    "            it.set_description(f'Best score: {statistics.mean(best_score_list):.4f}. Params: {param_str}')\n",
    "        else:\n",
    "            it.set_description(f'Params: {param_str}')\n",
    "        iter_score_list, iter_pred_dict = train_kfold_model(\n",
    "            train_model_fn=functools.partial(train_model_fn, param_dict),\n",
    "            fold_list=fold_list)\n",
    "        if best_score_list is None or statistics.mean(best_score_list) > statistics.mean(iter_score_list):\n",
    "            best_param_dict = param_dict\n",
    "            best_score_list = iter_score_list\n",
    "            best_pred_dict = iter_pred_dict\n",
    "            it.set_description(f'Best score: {statistics.mean(best_score_list):.4f}. Params: {param_str}')\n",
    "            if print_best_params:\n",
    "                print(f'Best params: {best_param_dict}')\n",
    "    assert best_param_dict is not None\n",
    "    assert best_score_list is not None\n",
    "    assert best_pred_dict is not None\n",
    "    return best_param_dict, best_score_list, best_pred_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _XY(t.NamedTuple):\n",
    "    x: np.ndarray\n",
    "    y: np.ndarray\n",
    "    feature_name_list: t.List[str]\n",
    "\n",
    "\n",
    "class _CatboostTrainer:\n",
    "    target: str\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_params: t.Optional[t.Dict[str, t.Any]] = None,\n",
    "            plot: bool = True,\n",
    "            model_path_template: t.Optional[Path] = None,\n",
    "            print_feature_importance: bool = False):\n",
    "        self._model_params = model_params if model_params is not None else {}\n",
    "        self._plot = plot\n",
    "        self._model_path_template = model_path_template\n",
    "        self._print_feature_importance = print_feature_importance\n",
    "\n",
    "    def _get_model(self) -> CatBoostRegressor:\n",
    "        return CatBoostRegressor(\n",
    "            task_type='GPU',\n",
    "            random_seed=SEED,\n",
    "            loss_function='RMSE',\n",
    "            **self._model_params)\n",
    "\n",
    "    def _is_feature_included(self, feature: str) -> bool:\n",
    "        return feature not in {\n",
    "            'text_id',\n",
    "            'full_text',\n",
    "            'cohesion',\n",
    "            'syntax',\n",
    "            'vocabulary',\n",
    "            'phraseology',\n",
    "            'grammar',\n",
    "            'conventions',\n",
    "            'fold',\n",
    "        }\n",
    "\n",
    "    def _convert_df_to_xy(self, df: pd.DataFrame, target: str) -> _XY:\n",
    "        feature_name_list = [\n",
    "            col for col in t.cast(t.List[str], df.columns)\n",
    "            if self._is_feature_included(col)\n",
    "        ]\n",
    "        x = df[feature_name_list].values\n",
    "        y = t.cast(np.ndarray, df[target].values)\n",
    "        return _XY(x=x, y=y, feature_name_list=feature_name_list)\n",
    "\n",
    "    def __call__(self, fold: int) -> t.Tuple[float, PredDict]:\n",
    "        train_df, valid_df = all_df[all_df['fold'] != fold], all_df[all_df['fold'] == fold]\n",
    "\n",
    "        booster = self._get_model()\n",
    "        train_xy = self._convert_df_to_xy(train_df, self.target)\n",
    "        valid_xy = self._convert_df_to_xy(valid_df, self.target)\n",
    "        booster.fit(\n",
    "            train_xy.x,\n",
    "            train_xy.y,\n",
    "            eval_set=(valid_xy.x, valid_xy.y),\n",
    "            plot=self._plot,\n",
    "            silent=True)\n",
    "        valid_y_pred = booster.predict(valid_xy.x)\n",
    "\n",
    "        if self._model_path_template is not None:\n",
    "            booster.save_model(str(format_path(self._model_path_template, target=self.target, fold=fold)))  # type: ignore\n",
    "        score = math.sqrt(mean_squared_error(y_true=valid_xy.y, y_pred=valid_y_pred))\n",
    "\n",
    "        if self._print_feature_importance:\n",
    "            for feature, imp_score in sorted(\n",
    "                    zip(train_xy.feature_name_list, booster.feature_importances_),\n",
    "                    key=lambda x: x[1],\n",
    "                    reverse=True):\n",
    "                print(f'{feature.ljust(50)} = {imp_score:.4f}')\n",
    "\n",
    "        return score, PredDict(zip(valid_df['text_id'].tolist(), [ensure_list(x) for x in valid_y_pred.tolist()]))\n",
    "\n",
    "\n",
    "class _SyntaxCatboostTrainer(_CatboostTrainer):\n",
    "    target = 'syntax'\n",
    "\n",
    "    def _get_model(self) -> CatBoostRegressor:\n",
    "        return CatBoostRegressor(\n",
    "            task_type='GPU',\n",
    "            random_seed=SEED,\n",
    "            loss_function='RMSE',\n",
    "            l2_leaf_reg=12.0,\n",
    "        )\n",
    "\n",
    "\n",
    "class _PhraseologyCatboostTrainer(_CatboostTrainer):\n",
    "    target = 'phraseology'\n",
    "\n",
    "    def _get_model(self) -> CatBoostRegressor:\n",
    "        return CatBoostRegressor(\n",
    "            task_type='GPU',\n",
    "            random_seed=SEED,\n",
    "            loss_function='RMSE',\n",
    "            l2_leaf_reg=12.0,\n",
    "        )\n",
    "\n",
    "\n",
    "class _GrammarCatboostTrainer(_CatboostTrainer):\n",
    "    target = 'grammar'\n",
    "\n",
    "    def _get_model(self) -> CatBoostRegressor:\n",
    "        return CatBoostRegressor(\n",
    "            task_type='GPU',\n",
    "            random_seed=SEED,\n",
    "            loss_function='RMSE',\n",
    "            l2_leaf_reg=12.0,\n",
    "        )\n",
    "\n",
    "\n",
    "class _ConventionsCatboostTrainer(_CatboostTrainer):\n",
    "    target = 'conventions'\n",
    "\n",
    "    def _get_model(self) -> CatBoostRegressor:\n",
    "        return CatBoostRegressor(\n",
    "            task_type='GPU',\n",
    "            random_seed=SEED,\n",
    "            loss_function='RMSE',\n",
    "            l2_leaf_reg=12.0,\n",
    "            learning_rate=0.025\n",
    "        )\n",
    "\n",
    "\n",
    "class _CohesionCatboostTrainer(_CatboostTrainer):\n",
    "    target = 'cohesion'\n",
    "\n",
    "    def _get_model(self) -> CatBoostRegressor:\n",
    "        return CatBoostRegressor(\n",
    "            task_type='GPU',\n",
    "            random_seed=SEED,\n",
    "            loss_function='RMSE',)\n",
    "\n",
    "    def _is_feature_included(self, feature: str) -> bool:\n",
    "        return super()._is_feature_included(feature) and not feature.endswith('_l1')\n",
    "\n",
    "\n",
    "class _VocabularyCatboostTrainer(_CatboostTrainer):\n",
    "    target = 'vocabulary'\n",
    "\n",
    "    def _get_model(self) -> CatBoostRegressor:\n",
    "        return CatBoostRegressor(\n",
    "            task_type='GPU',\n",
    "            random_seed=SEED,\n",
    "            loss_function='RMSE',\n",
    "            max_depth=5,\n",
    "            **self._model_params,\n",
    "        )\n",
    "\n",
    "    def _is_feature_included(self, feature: str) -> bool:\n",
    "        return super()._is_feature_included(feature) and not feature.endswith('_l1')\n",
    "\n",
    "\n",
    "trainer = _VocabularyCatboostTrainer(\n",
    "    print_feature_importance=True,\n",
    "    model_path_template=MODEL_DIR / 'fp-ell-models-boosting/lvl2-catboost-{target}-cv2-fold_{fold}.cbm',\n",
    ")\n",
    "score_list, oof_pred_dict= train_kfold_model(\n",
    "        train_model_fn=trainer,\n",
    "        fold_list=FOLD_LIST)\n",
    "oof_pred_dict.save_to_csv(\n",
    "    OOF_DIR / f'lvl2-catboost-{trainer.target}-cv2.csv',\n",
    "    score_col_name_list=[f'{trainer.target}_score'])\n",
    "print(f'Mean score: {statistics.mean(score_list):.4f}')\n",
    "build_fold_result_df(fold_list=FOLD_LIST, score_list=score_list)\n",
    "# best_param_dict, score_list, _ = grid_search(\n",
    "#     train_model_fn=lambda params, fold: _VocabularyCatboostTrainer(params, plot=False)(fold),\n",
    "#     param_plan={\n",
    "#         'learning_rate': [None, 0.06, 0.065, 0.07, 0.075],\n",
    "#         'iterations': [None, 500, 1500],\n",
    "#     },\n",
    "#     fold_list=FOLD_LIST,\n",
    "#     print_best_params=True)\n",
    "# build_fold_result_df(fold_list=FOLD_LIST, score_list=score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('kaggle-fp-ell')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4646e3fde12bd3179c3551877f577659b7a8fa6d1b23b85720655ff3fa8cde14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
