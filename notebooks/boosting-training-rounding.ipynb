{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import math\n",
    "import os\n",
    "import statistics\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "import kaggle_toolbox.features.generation as features\n",
    "import kaggle_toolbox.nlp.features as text_features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from kaggle_toolbox.environment import Environment\n",
    "from kaggle_toolbox.features.transform import contiguous_to_categorical\n",
    "from kaggle_toolbox.path import format_path\n",
    "from kaggle_toolbox.prediction import PredDict\n",
    "from kaggle_toolbox.progress import NotebookProgressBar\n",
    "from kaggle_toolbox.trainer import train_kfold_model\n",
    "from kaggle_toolbox.typing import ensure_list\n",
    "from kaggle_toolbox.validation import analyze_val_strategy, build_fold_result_df\n",
    "from sklearn.metrics import f1_score\n",
    "from textstat import textstat\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LIST = [\n",
    "    'cohesion',\n",
    "    'syntax',\n",
    "    'vocabulary',\n",
    "    'phraseology',\n",
    "    'grammar',\n",
    "    'conventions',\n",
    "]\n",
    "TARGET = TARGET_LIST[0]\n",
    "\n",
    "SEED = 42\n",
    "NUM_FOLDS = 5\n",
    "FOLD_LIST = [0, 1, 2, 3, 4]\n",
    "\n",
    "ENVIRONMENT = os.getenv('__KGLTBX_ENVIRONMENT', 'laptop')\n",
    "_env = Environment(ENVIRONMENT)\n",
    "\n",
    "ROOT_DIR = _env.param(\n",
    "    kaggle=Path('/kaggle'),\n",
    "    colab=Path('/content/drive/MyDrive'),\n",
    "    laptop=Path('/kaggle'))\n",
    "DATA_DIR = _env.param(\n",
    "    kaggle=ROOT_DIR / 'input',\n",
    "    colab=ROOT_DIR / 'data',\n",
    "    laptop=ROOT_DIR / 'data')\n",
    "FP_ELL_DATASET_DIR = _env.param(\n",
    "    kaggle=DATA_DIR / 'feedback-prize-english-language-learning',\n",
    "    colab=DATA_DIR / 'fp-ell',\n",
    "    laptop=DATA_DIR / 'fp-ell')\n",
    "MODEL_DIR = _env.param(\n",
    "    kaggle=ROOT_DIR / 'working',\n",
    "    colab=ROOT_DIR / 'models/fp-ell',\n",
    "    laptop=ROOT_DIR / 'models')\n",
    "OOF_DIR = _env.param(\n",
    "    kaggle=ROOT_DIR / 'working',\n",
    "    colab=ROOT_DIR / 'oof/fp-ell',\n",
    "    laptop=ROOT_DIR / 'oof')\n",
    "\n",
    "TARGET_TO_LVL1_OOF_PATH_DICT = {\n",
    "    'cohesion': OOF_DIR / 'cohesion-v1-layer_norm-ep_4-valfreq_0p25-pooler_att-full.csv',\n",
    "    'syntax': OOF_DIR / 'syntax-v1-layer_norm-ep_3-valfreq_0p25-full.csv',\n",
    "    'vocabulary': OOF_DIR / 'vocabulary-v1-layer_norm-ep_3-valfreq_0p25-std_init.csv',\n",
    "    'phraseology': OOF_DIR / 'phraseology-v1-layer_norm-ep_3-valfreq_0p25-std_init-full.csv',\n",
    "    'grammar': OOF_DIR / 'grammar-v1-lnorm-ep_4-valfreq_0p25-sqzr_cat_9_to_12-full.csv',\n",
    "    'conventions': OOF_DIR / 'conventions-v1-layer_norm-ep_3-valfreq_0p25-full.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LVL1_SCORE_FEATURE_LIST = [f'{target}_lvl1_score' for target in TARGET_LIST]\n",
    "_FEATURE_GENERATOR_LIST = [\n",
    "    # Score-based\n",
    "    *features.L1Distance.pairwise_from_feature_list(_LVL1_SCORE_FEATURE_LIST),\n",
    "    features.Mean(name='lvl1_mean', feature_list=_LVL1_SCORE_FEATURE_LIST),\n",
    "    features.Stdev(name='lvl1_std', feature_list=_LVL1_SCORE_FEATURE_LIST),\n",
    "    # Custom simple\n",
    "    text_features.SubstrCount(name='num_commas', substr=','),\n",
    "    text_features.SubstrCount(name='num_dots', substr='.'),\n",
    "    text_features.SubstrCount(name='num_colons', substr=':'),\n",
    "    text_features.SubstrCount(name='num_semicolons', substr=';'),\n",
    "    text_features.SubstrCount(name='num_ellipsis', substr='...'),\n",
    "    text_features.SubstrCount(name='num_newlines', substr='\\n'),\n",
    "    text_features.SubstrCount(name='num_spaces', substr=' '),\n",
    "    # TextStat simple\n",
    "    text_features.Func(name='syllable_count', func=textstat.syllable_count),\n",
    "    text_features.Func(name='lexicon_count', func=functools.partial(textstat.lexicon_count, removepunct=True)),\n",
    "    text_features.Func(name='char_count', func=functools.partial(textstat.char_count, ignore_spaces=True)),\n",
    "    text_features.Func(name='letter_count', func=functools.partial(textstat.letter_count, ignore_spaces=True)),\n",
    "    text_features.Func(name='polysyllabcount', func=functools.partial(textstat.polysyllabcount)),\n",
    "    text_features.Func(name='monosyllabcount', func=functools.partial(textstat.monosyllabcount)),\n",
    "    # Custom complex\n",
    "    features.Div(name='ratio_commas', lhs_feature='num_commas', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_dots', lhs_feature='num_dots', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_colons', lhs_feature='num_colons', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_semicolons', lhs_feature='num_semicolons', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_ellipsis', lhs_feature='num_ellipsis', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_newlines', lhs_feature='num_newlines', rhs_feature='char_count'),\n",
    "    features.Div(name='ratio_spaces', lhs_feature='num_spaces', rhs_feature='char_count'),\n",
    "    # TextStat complex\n",
    "    text_features.Func(name='flesch_reading_ease', func=textstat.flesch_reading_ease),\n",
    "    text_features.Func(name='flesch_kincaid_grade', func=textstat.flesch_kincaid_grade),\n",
    "    text_features.Func(name='gunning_fog', func=textstat.gunning_fog),\n",
    "    text_features.Func(name='smog_index', func=textstat.smog_index),\n",
    "    text_features.Func(name='automated_readability_index', func=textstat.automated_readability_index),\n",
    "    text_features.Func(name='coleman_liau_index', func=textstat.coleman_liau_index),\n",
    "    text_features.Func(name='linsear_write_formula', func=textstat.linsear_write_formula),\n",
    "    text_features.Func(name='dale_chall_readability_score', func=textstat.dale_chall_readability_score),\n",
    "    text_features.Func(name='text_standard', func=functools.partial(textstat.text_standard, float_output=True)),  # type: ignore\n",
    "    text_features.Func(name='spache_readability', func=textstat.spache_readability),\n",
    "    text_features.Func(name='mcalpine_eflaw', func=textstat.mcalpine_eflaw),\n",
    "    text_features.Func(name='reading_time', func=functools.partial(textstat.reading_time, ms_per_char=14.69)),\n",
    "]\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    text_srs = df['full_text']\n",
    "\n",
    "    feature_arr_dict = text_features.generate_text_features(\n",
    "        generator_list=_FEATURE_GENERATOR_LIST,\n",
    "        text_seq=text_srs.tolist(),\n",
    "        progress_bar=NotebookProgressBar(),\n",
    "        init_feature_array_dict={\n",
    "            f'{target}_lvl1_score': df[f'{target}_lvl1_score'].values\n",
    "            for target in TARGET_LIST\n",
    "        })  # type: ignore\n",
    "    for feature_name, feature_arr in feature_arr_dict.items():\n",
    "        df[feature_name] = feature_arr\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43b7843f17e41e0b524ded15b250092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cohesion_lvl1_score_cohesion_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b911bc2967de411c8e373822b9579db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cohesion_lvl1_score_syntax_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7946460ec9604d12b4ebdf3b3cf6bc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cohesion_lvl1_score_vocabulary_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029accd0bc1417fa07f9d260b2e2f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cohesion_lvl1_score_phraseology_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0a201843ee48569254abbaa997a345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cohesion_lvl1_score_grammar_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34a4759c98b42caa9ded93875210358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "cohesion_lvl1_score_conventions_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31b25815dd8476aae5e073925e9175b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "syntax_lvl1_score_syntax_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf1d4de44d54f0297416fe2240691fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "syntax_lvl1_score_vocabulary_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cfb7909dc242788ec39b80647efd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "syntax_lvl1_score_phraseology_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee31ee1657744018f834591778e3ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "syntax_lvl1_score_grammar_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712b9a2b98f943c6abbe848263688b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "syntax_lvl1_score_conventions_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c622f1e5e04817ad389b204d2d733e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary_lvl1_score_vocabulary_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044f01d2086e4ee484b1fd54a927057b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary_lvl1_score_phraseology_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230de20fcf7046eeb47f1dac8cb8dd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary_lvl1_score_grammar_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5836139783643f3abf4dc5033d19646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocabulary_lvl1_score_conventions_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59fb7ecf4ff448759f89fbb35d15fb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "phraseology_lvl1_score_phraseology_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6001227c51e4e4289315eb2a76d5b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "phraseology_lvl1_score_grammar_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26a69a68980345169b2cdc180530cb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "phraseology_lvl1_score_conventions_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0b3a9302929488c85fdbbda02f3811a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "grammar_lvl1_score_grammar_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb00ecdafe2420499d45adf2ded3742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "grammar_lvl1_score_conventions_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5544bdf7b50477b9eecd6bbef4c1b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "conventions_lvl1_score_conventions_lvl1_score_l1:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af60de880d24c469e6db8bef4a73585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lvl1_mean:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d32da08b994527843870508a49968a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lvl1_std:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd95cb2d48c47d9927cc1e3a8b3e9c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "num_commas:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa3531383ac4b58886884b7374bd9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "num_dots:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0d736d3675440aba168f9812865097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "num_colons:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4175369f39bc4c288ef3271adfd33fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "num_semicolons:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684211777e3c48ffb3f7f8724d8fc9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "num_ellipsis:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e161a4d3736144edb647f66f1a93f0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "num_newlines:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c28666c6f74bd1bfaa41e4c2e647e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "num_spaces:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e02523e0bb64884874a260f8557b590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "syllable_count:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69707582509349e58b7904f69a6652f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lexicon_count:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0857b641fcc8482bb7334c325316eee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "char_count:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b0de14002f4db0ad5246690b841688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "letter_count:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca073bd88d694084a6e71d759be71a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "polysyllabcount:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdee2c84576c478e8d671fe6029550d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "monosyllabcount:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba34832c65b431c9b87305e4ca868f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ratio_commas:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d4ffcba1554eb5ac29c0bb112120f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ratio_dots:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc440a6bdf82431785a141b12cef36c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ratio_colons:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa5df620fe8490a8e0070303a503e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ratio_semicolons:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b233f4767d4e44a29d25e33fcb75a965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ratio_ellipsis:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbcf0b34d62241c9b554535aee454b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ratio_newlines:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd78a029a41d49ba89823b3cccc291d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ratio_spaces:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a602d19a9e7141a4b8177ae0e8658356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flesch_reading_ease:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38003ff63834355af0481af99e8c977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flesch_kincaid_grade:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e46e164b76d44ecbfa7cb38f90a9cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gunning_fog:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7476f359e63f4e3caebced703350594a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "smog_index:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c738801dc64dde9f2c888eb4bfe3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "automated_readability_index:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c3727e8f0e4c0086937b372448e58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "coleman_liau_index:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4650433d66c4f87a00c8aa42f022e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "linsear_write_formula:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b873690feef4d8394ffd25ca0160c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dale_chall_readability_score:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e407159ef90649c2890f5940fabf14ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_standard:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda58a658a55437b994c38831881adeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spache_readability:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5a0b99e1e949b3a33eda3de4e56da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mcalpine_eflaw:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7debfda43e74fbd86709c4892bd48f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "reading_time:   0%|          | 0/3911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>cohesion_mean</th>\n",
       "      <th>syntax_mean</th>\n",
       "      <th>vocabulary_mean</th>\n",
       "      <th>phraseology_mean</th>\n",
       "      <th>grammar_mean</th>\n",
       "      <th>conventions_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>782</td>\n",
       "      <td>3.077366</td>\n",
       "      <td>2.971867</td>\n",
       "      <td>3.205243</td>\n",
       "      <td>3.065857</td>\n",
       "      <td>2.959719</td>\n",
       "      <td>3.035166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>783</td>\n",
       "      <td>3.125160</td>\n",
       "      <td>3.007024</td>\n",
       "      <td>3.226054</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>3.015964</td>\n",
       "      <td>3.079183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>782</td>\n",
       "      <td>3.140665</td>\n",
       "      <td>3.068414</td>\n",
       "      <td>3.258312</td>\n",
       "      <td>3.138747</td>\n",
       "      <td>3.069693</td>\n",
       "      <td>3.116368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>782</td>\n",
       "      <td>3.131074</td>\n",
       "      <td>3.048593</td>\n",
       "      <td>3.245524</td>\n",
       "      <td>3.125959</td>\n",
       "      <td>3.042839</td>\n",
       "      <td>3.074169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>782</td>\n",
       "      <td>3.161125</td>\n",
       "      <td>3.045396</td>\n",
       "      <td>3.243606</td>\n",
       "      <td>3.142583</td>\n",
       "      <td>3.076087</td>\n",
       "      <td>3.100384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  num_samples  ...  grammar_mean  conventions_mean\n",
       "0     0          782  ...      2.959719          3.035166\n",
       "1     1          783  ...      3.015964          3.079183\n",
       "2     2          782  ...      3.069693          3.116368\n",
       "3     3          782  ...      3.042839          3.074169\n",
       "4     4          782  ...      3.076087          3.100384\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _read_data(\n",
    "        dataset_dir_path: Path,\n",
    "        target_list: t.List[str],\n",
    "        target_to_lvl1_oof_path_dict: t.Dict[str, Path],\n",
    "        num_folds: int,\n",
    "        seed: int) -> pd.DataFrame:\n",
    "    all_df = pd.read_csv(dataset_dir_path / 'train.csv')\n",
    "    target_arr = contiguous_to_categorical(all_df[target_list].values)\n",
    "\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    for fold_, (_, v_) in enumerate(mskf.split(X=all_df, y=target_arr)):\n",
    "        all_df.loc[v_, 'fold'] = fold_\n",
    "\n",
    "    for target in target_list:\n",
    "        all_df = all_df.merge(\n",
    "            pd.read_csv(target_to_lvl1_oof_path_dict[target])\n",
    "                .rename({\n",
    "                    'id': 'text_id',\n",
    "                    f'{target}_score': f'{target}_lvl1_score',\n",
    "                }, axis=1),\n",
    "            left_on='text_id',\n",
    "            right_on='text_id')\n",
    "        all_df[f'{target}_is_roundable'] = (all_df[f'{target}_lvl1_score'] - all_df[target]).abs() <= 0.25\n",
    "\n",
    "    all_df = build_features(all_df)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "all_df = _read_data(\n",
    "    dataset_dir_path=FP_ELL_DATASET_DIR,\n",
    "    target_list=TARGET_LIST,\n",
    "    target_to_lvl1_oof_path_dict=TARGET_TO_LVL1_OOF_PATH_DICT,\n",
    "    num_folds=NUM_FOLDS,\n",
    "    seed=SEED)\n",
    "\n",
    "analyze_val_strategy(all_df, target_list=TARGET_LIST, num_folds=NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>fold</th>\n",
       "      <th>cohesion_lvl1_score</th>\n",
       "      <th>cohesion_is_roundable</th>\n",
       "      <th>syntax_lvl1_score</th>\n",
       "      <th>syntax_is_roundable</th>\n",
       "      <th>vocabulary_lvl1_score</th>\n",
       "      <th>vocabulary_is_roundable</th>\n",
       "      <th>phraseology_lvl1_score</th>\n",
       "      <th>phraseology_is_roundable</th>\n",
       "      <th>grammar_lvl1_score</th>\n",
       "      <th>grammar_is_roundable</th>\n",
       "      <th>conventions_lvl1_score</th>\n",
       "      <th>conventions_is_roundable</th>\n",
       "      <th>cohesion_lvl1_score_cohesion_lvl1_score_l1</th>\n",
       "      <th>cohesion_lvl1_score_syntax_lvl1_score_l1</th>\n",
       "      <th>cohesion_lvl1_score_vocabulary_lvl1_score_l1</th>\n",
       "      <th>cohesion_lvl1_score_phraseology_lvl1_score_l1</th>\n",
       "      <th>cohesion_lvl1_score_grammar_lvl1_score_l1</th>\n",
       "      <th>cohesion_lvl1_score_conventions_lvl1_score_l1</th>\n",
       "      <th>syntax_lvl1_score_syntax_lvl1_score_l1</th>\n",
       "      <th>syntax_lvl1_score_vocabulary_lvl1_score_l1</th>\n",
       "      <th>syntax_lvl1_score_phraseology_lvl1_score_l1</th>\n",
       "      <th>syntax_lvl1_score_grammar_lvl1_score_l1</th>\n",
       "      <th>syntax_lvl1_score_conventions_lvl1_score_l1</th>\n",
       "      <th>vocabulary_lvl1_score_vocabulary_lvl1_score_l1</th>\n",
       "      <th>vocabulary_lvl1_score_phraseology_lvl1_score_l1</th>\n",
       "      <th>vocabulary_lvl1_score_grammar_lvl1_score_l1</th>\n",
       "      <th>vocabulary_lvl1_score_conventions_lvl1_score_l1</th>\n",
       "      <th>phraseology_lvl1_score_phraseology_lvl1_score_l1</th>\n",
       "      <th>phraseology_lvl1_score_grammar_lvl1_score_l1</th>\n",
       "      <th>phraseology_lvl1_score_conventions_lvl1_score_l1</th>\n",
       "      <th>grammar_lvl1_score_grammar_lvl1_score_l1</th>\n",
       "      <th>grammar_lvl1_score_conventions_lvl1_score_l1</th>\n",
       "      <th>conventions_lvl1_score_conventions_lvl1_score_l1</th>\n",
       "      <th>lvl1_mean</th>\n",
       "      <th>lvl1_std</th>\n",
       "      <th>num_commas</th>\n",
       "      <th>num_dots</th>\n",
       "      <th>num_colons</th>\n",
       "      <th>num_semicolons</th>\n",
       "      <th>num_ellipsis</th>\n",
       "      <th>num_newlines</th>\n",
       "      <th>num_spaces</th>\n",
       "      <th>syllable_count</th>\n",
       "      <th>lexicon_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>letter_count</th>\n",
       "      <th>polysyllabcount</th>\n",
       "      <th>monosyllabcount</th>\n",
       "      <th>ratio_commas</th>\n",
       "      <th>ratio_dots</th>\n",
       "      <th>ratio_colons</th>\n",
       "      <th>ratio_semicolons</th>\n",
       "      <th>ratio_ellipsis</th>\n",
       "      <th>ratio_newlines</th>\n",
       "      <th>ratio_spaces</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>automated_readability_index</th>\n",
       "      <th>coleman_liau_index</th>\n",
       "      <th>linsear_write_formula</th>\n",
       "      <th>dale_chall_readability_score</th>\n",
       "      <th>text_standard</th>\n",
       "      <th>spache_readability</th>\n",
       "      <th>mcalpine_eflaw</th>\n",
       "      <th>reading_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.855740</td>\n",
       "      <td>False</td>\n",
       "      <td>2.950954</td>\n",
       "      <td>False</td>\n",
       "      <td>3.219144</td>\n",
       "      <td>True</td>\n",
       "      <td>3.222088</td>\n",
       "      <td>True</td>\n",
       "      <td>3.093439</td>\n",
       "      <td>False</td>\n",
       "      <td>2.753647</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095214</td>\n",
       "      <td>0.363405</td>\n",
       "      <td>0.366349</td>\n",
       "      <td>0.237699</td>\n",
       "      <td>0.102093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.268190</td>\n",
       "      <td>0.271134</td>\n",
       "      <td>0.142485</td>\n",
       "      <td>0.197307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.125705</td>\n",
       "      <td>0.465497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128649</td>\n",
       "      <td>0.468441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.015835</td>\n",
       "      <td>0.177238</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>321</td>\n",
       "      <td>261</td>\n",
       "      <td>1110</td>\n",
       "      <td>1089</td>\n",
       "      <td>11</td>\n",
       "      <td>212</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.016216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.244144</td>\n",
       "      <td>90.60</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.57</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.31</td>\n",
       "      <td>8.000</td>\n",
       "      <td>5.99</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>20.2</td>\n",
       "      <td>16.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.784366</td>\n",
       "      <td>False</td>\n",
       "      <td>2.648692</td>\n",
       "      <td>True</td>\n",
       "      <td>2.870578</td>\n",
       "      <td>True</td>\n",
       "      <td>2.740792</td>\n",
       "      <td>False</td>\n",
       "      <td>2.370473</td>\n",
       "      <td>False</td>\n",
       "      <td>2.674716</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135674</td>\n",
       "      <td>0.086212</td>\n",
       "      <td>0.043575</td>\n",
       "      <td>0.413893</td>\n",
       "      <td>0.109650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221886</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.278219</td>\n",
       "      <td>0.026025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129786</td>\n",
       "      <td>0.500105</td>\n",
       "      <td>0.195862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370318</td>\n",
       "      <td>0.066075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.304243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.681603</td>\n",
       "      <td>0.156901</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>666</td>\n",
       "      <td>533</td>\n",
       "      <td>2098</td>\n",
       "      <td>2077</td>\n",
       "      <td>33</td>\n",
       "      <td>433</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.251192</td>\n",
       "      <td>66.64</td>\n",
       "      <td>13.4</td>\n",
       "      <td>15.47</td>\n",
       "      <td>11.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>5.93</td>\n",
       "      <td>11.200</td>\n",
       "      <td>2.45</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>58.5</td>\n",
       "      <td>30.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.891909</td>\n",
       "      <td>True</td>\n",
       "      <td>3.007077</td>\n",
       "      <td>False</td>\n",
       "      <td>3.099227</td>\n",
       "      <td>True</td>\n",
       "      <td>2.975205</td>\n",
       "      <td>True</td>\n",
       "      <td>2.962219</td>\n",
       "      <td>True</td>\n",
       "      <td>3.016932</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115168</td>\n",
       "      <td>0.207318</td>\n",
       "      <td>0.083296</td>\n",
       "      <td>0.070310</td>\n",
       "      <td>0.125023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.031872</td>\n",
       "      <td>0.044858</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124022</td>\n",
       "      <td>0.137008</td>\n",
       "      <td>0.082295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.041727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.992095</td>\n",
       "      <td>0.062628</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>411</td>\n",
       "      <td>320</td>\n",
       "      <td>1343</td>\n",
       "      <td>1307</td>\n",
       "      <td>23</td>\n",
       "      <td>258</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.014147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.236783</td>\n",
       "      <td>79.80</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.22</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.09</td>\n",
       "      <td>6.625</td>\n",
       "      <td>5.95</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.64</td>\n",
       "      <td>23.6</td>\n",
       "      <td>19.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  ... reading_time\n",
       "0  0016926B079C  ...        16.31\n",
       "1  0022683E9EA5  ...        30.82\n",
       "2  00299B378633  ...        19.73\n",
       "\n",
       "[3 rows x 76 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(\n",
    "        train_model_fn: t.Callable[[t.Dict[str, t.Any], int], t.Tuple[float, PredDict]],\n",
    "        param_plan: t.Dict[str, t.List[t.Any]],\n",
    "        fold_list: t.List[int],\n",
    "        print_best_params: bool = False) -> t.Tuple[t.Dict[str, t.Any], t.List[float], PredDict]:\n",
    "    param_name_list = list(param_plan.keys())\n",
    "    param_comb_list = list(itertools.product(*[param_plan[param_name] for param_name in param_name_list]))\n",
    "    best_param_dict, best_score_list, best_pred_dict = None, None, None\n",
    "    it = tqdm(param_comb_list)\n",
    "    for param_value_tuple in it:\n",
    "        param_value_list = list(param_value_tuple)\n",
    "        param_dict = dict(zip(param_name_list, param_value_list))\n",
    "        param_str = ', '.join([f'{k} = {v}' for k, v in param_dict.items()])\n",
    "        if best_score_list is not None:\n",
    "            it.set_description(f'Best score: {statistics.mean(best_score_list):.4f}. Params: {param_str}')\n",
    "        else:\n",
    "            it.set_description(f'Params: {param_str}')\n",
    "        iter_score_list, iter_pred_dict = train_kfold_model(\n",
    "            train_model_fn=functools.partial(train_model_fn, param_dict),\n",
    "            fold_list=fold_list)\n",
    "        if best_score_list is None or statistics.mean(best_score_list) > statistics.mean(iter_score_list):\n",
    "            best_param_dict = param_dict\n",
    "            best_score_list = iter_score_list\n",
    "            best_pred_dict = iter_pred_dict\n",
    "            it.set_description(f'Best score: {statistics.mean(best_score_list):.4f}. Params: {param_str}')\n",
    "            if print_best_params:\n",
    "                print(f'Best params: {best_param_dict}')\n",
    "    assert best_param_dict is not None\n",
    "    assert best_score_list is not None\n",
    "    assert best_pred_dict is not None\n",
    "    return best_param_dict, best_score_list, best_pred_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47104ad02d314fff8ae72b0683202559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/sklearn/metrics/_classification.py:111\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     unique_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munion1d(y_true, y_pred)\n\u001b[1;32m    112\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m     \u001b[39m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[39m# strings. So we raise a meaningful error\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munion1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/numpy/lib/arraysetops.py:781\u001b[0m, in \u001b[0;36munion1d\u001b[0;34m(ar1, ar2)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[39mFind the union of two arrays.\u001b[39;00m\n\u001b[1;32m    751\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[39marray([1, 2, 3, 4, 6])\u001b[39;00m\n\u001b[1;32m    780\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 781\u001b[0m \u001b[39mreturn\u001b[39;00m unique(np\u001b[39m.\u001b[39;49mconcatenate((ar1, ar2), axis\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'bool'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 82\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_is_feature_included(feature) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m feature\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m_l1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m trainer \u001b[39m=\u001b[39m CohesionCatboostTrainer()\n\u001b[0;32m---> 82\u001b[0m score_list, oof_pred_dict\u001b[39m=\u001b[39m train_kfold_model(\n\u001b[1;32m     83\u001b[0m         train_model_fn\u001b[39m=\u001b[39;49mtrainer,\n\u001b[1;32m     84\u001b[0m         fold_list\u001b[39m=\u001b[39;49mFOLD_LIST)\n\u001b[1;32m     85\u001b[0m oof_pred_dict\u001b[39m.\u001b[39msave_to_csv(\n\u001b[1;32m     86\u001b[0m     OOF_DIR \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrounding-catboost-\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mtarget\u001b[39m}\u001b[39;00m\u001b[39m-cv2.csv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     87\u001b[0m     score_col_name_list\u001b[39m=\u001b[39m[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mtarget\u001b[39m}\u001b[39;00m\u001b[39m_score\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     88\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMean score: \u001b[39m\u001b[39m{\u001b[39;00mstatistics\u001b[39m.\u001b[39mmean(score_list)\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/kaggle_toolbox/trainer.py:278\u001b[0m, in \u001b[0;36mtrain_kfold_model\u001b[0;34m(train_model_fn, fold_list)\u001b[0m\n\u001b[1;32m    276\u001b[0m pred_dict \u001b[39m=\u001b[39m PredDict()\n\u001b[1;32m    277\u001b[0m \u001b[39mfor\u001b[39;00m fold \u001b[39min\u001b[39;00m fold_list:\n\u001b[0;32m--> 278\u001b[0m     model_score, model_pred_dict \u001b[39m=\u001b[39m train_model_fn(fold)\n\u001b[1;32m    279\u001b[0m     score_list\u001b[39m.\u001b[39mappend(model_score)\n\u001b[1;32m    280\u001b[0m     pred_dict\u001b[39m.\u001b[39mupdate(model_pred_dict)\n",
      "Cell \u001b[0;32mIn [14], line 62\u001b[0m, in \u001b[0;36m_CatboostTrainer.__call__\u001b[0;34m(self, fold)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_path_template \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     booster\u001b[39m.\u001b[39msave_model(\u001b[39mstr\u001b[39m(format_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model_path_template, target\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget, fold\u001b[39m=\u001b[39mfold)))  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m score \u001b[39m=\u001b[39m f1_score(y_true\u001b[39m=\u001b[39;49mvalid_xy\u001b[39m.\u001b[39;49my, y_pred\u001b[39m=\u001b[39;49mvalid_y_pred)\n\u001b[1;32m     64\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_feature_importance:\n\u001b[1;32m     65\u001b[0m     \u001b[39mfor\u001b[39;00m feature, imp_score \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(\n\u001b[1;32m     66\u001b[0m             \u001b[39mzip\u001b[39m(train_xy\u001b[39m.\u001b[39mfeature_name_list, booster\u001b[39m.\u001b[39mfeature_importances_),\n\u001b[1;32m     67\u001b[0m             key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m1\u001b[39m],\n\u001b[1;32m     68\u001b[0m             reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1136\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[1;32m   1002\u001b[0m     y_true,\n\u001b[1;32m   1003\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1010\u001b[0m ):\n\u001b[1;32m   1011\u001b[0m     \u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \n\u001b[1;32m   1013\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1134\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1136\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[1;32m   1137\u001b[0m         y_true,\n\u001b[1;32m   1138\u001b[0m         y_pred,\n\u001b[1;32m   1139\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1140\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1141\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1142\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1143\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1144\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1145\u001b[0m     )\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1277\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[1;32m   1149\u001b[0m     y_true,\n\u001b[1;32m   1150\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1158\u001b[0m ):\n\u001b[1;32m   1159\u001b[0m     \u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1160\u001b[0m \n\u001b[1;32m   1161\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[1;32m   1275\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1277\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1278\u001b[0m         y_true,\n\u001b[1;32m   1279\u001b[0m         y_pred,\n\u001b[1;32m   1280\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m   1281\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1282\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1283\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1284\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1285\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1286\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1287\u001b[0m     )\n\u001b[1;32m   1288\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1563\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1562\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1563\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1565\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1566\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1364\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1362\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1364\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1365\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1367\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.virtualenvs/kaggle-fp-ell/lib/python3.10/site-packages/sklearn/metrics/_classification.py:117\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    111\u001b[0m     unique_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munion1d(y_true, y_pred)\n\u001b[1;32m    112\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m     \u001b[39m# We expect y_true and y_pred to be of the same data type.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m# If `y_true` was provided to the classifier as strings,\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39m# `y_pred` given by the classifier will also be encoded with\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[39m# strings. So we raise a meaningful error\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    118\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLabels in y_true and y_pred should be of the same type. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    119\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot y_true=\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_true)\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    120\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred=\u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39munique(y_pred)\u001b[39m}\u001b[39;00m\u001b[39m. Make sure that the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpredictions provided by the classifier coincides with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe true labels.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unique_values) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    125\u001b[0m     y_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Labels in y_true and y_pred should be of the same type. Got y_true=[False  True] and y_pred=['False' 'True']. Make sure that the predictions provided by the classifier coincides with the true labels."
     ]
    }
   ],
   "source": [
    "class _XY(t.NamedTuple):\n",
    "    x: np.ndarray\n",
    "    y: np.ndarray\n",
    "    feature_name_list: t.List[str]\n",
    "\n",
    "\n",
    "class _CatboostTrainer:\n",
    "    target: str\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            model_params: t.Optional[t.Dict[str, t.Any]] = None,\n",
    "            plot: bool = True,\n",
    "            model_path_template: t.Optional[Path] = None,\n",
    "            print_feature_importance: bool = False):\n",
    "        self._model_params = model_params if model_params is not None else {}\n",
    "        self._plot = plot\n",
    "        self._model_path_template = model_path_template\n",
    "        self._print_feature_importance = print_feature_importance\n",
    "\n",
    "    def _get_model(self) -> CatBoostClassifier:\n",
    "        return CatBoostClassifier(\n",
    "            task_type='GPU',\n",
    "            random_seed=SEED,\n",
    "            eval_metric='F1',\n",
    "            **self._model_params)\n",
    "\n",
    "    def _is_feature_included(self, feature: str) -> bool:\n",
    "        return feature not in {\n",
    "            'text_id',\n",
    "            'full_text',\n",
    "            'fold',\n",
    "            *TARGET_LIST,\n",
    "            *[f'{target}_is_roundable' for target in TARGET_LIST],\n",
    "        }\n",
    "\n",
    "    def _convert_df_to_xy(self, df: pd.DataFrame, target: str) -> _XY:\n",
    "        feature_name_list = [\n",
    "            col for col in t.cast(t.List[str], df.columns)\n",
    "            if self._is_feature_included(col)\n",
    "        ]\n",
    "        x = df[feature_name_list].values\n",
    "        y = t.cast(np.ndarray, df[f'{target}_is_roundable'].values)\n",
    "        return _XY(x=x, y=y, feature_name_list=feature_name_list)\n",
    "\n",
    "    def __call__(self, fold: int) -> t.Tuple[float, PredDict]:\n",
    "        train_df, valid_df = all_df[all_df['fold'] != fold], all_df[all_df['fold'] == fold]\n",
    "\n",
    "        booster = self._get_model()\n",
    "        train_xy = self._convert_df_to_xy(train_df, self.target)\n",
    "        valid_xy = self._convert_df_to_xy(valid_df, self.target)\n",
    "        booster.fit(\n",
    "            train_xy.x,\n",
    "            train_xy.y,\n",
    "            eval_set=(valid_xy.x, valid_xy.y),\n",
    "            plot=self._plot,\n",
    "            silent=True)\n",
    "        valid_y_pred = booster.predict(valid_xy.x)\n",
    "\n",
    "        if self._model_path_template is not None:\n",
    "            booster.save_model(str(format_path(self._model_path_template, target=self.target, fold=fold)))  # type: ignore\n",
    "        score = f1_score(y_true=valid_xy.y, y_pred=valid_y_pred)\n",
    "\n",
    "        if self._print_feature_importance:\n",
    "            for feature, imp_score in sorted(\n",
    "                    zip(train_xy.feature_name_list, booster.feature_importances_),\n",
    "                    key=lambda x: x[1],\n",
    "                    reverse=True):\n",
    "                print(f'{feature.ljust(50)} = {imp_score:.4f}')\n",
    "\n",
    "        return float(score), PredDict(zip(valid_df['text_id'].tolist(), [ensure_list(x) for x in valid_y_pred.tolist()]))\n",
    "\n",
    "\n",
    "class CohesionCatboostTrainer(_CatboostTrainer):\n",
    "    target = 'cohesion'\n",
    "\n",
    "    def _is_feature_included(self, feature: str) -> bool:\n",
    "        return super()._is_feature_included(feature) and not feature.endswith('_l1')\n",
    "\n",
    "\n",
    "trainer = CohesionCatboostTrainer()\n",
    "score_list, oof_pred_dict= train_kfold_model(\n",
    "        train_model_fn=trainer,\n",
    "        fold_list=FOLD_LIST)\n",
    "oof_pred_dict.save_to_csv(\n",
    "    OOF_DIR / f'rounding-catboost-{trainer.target}-cv2.csv',\n",
    "    score_col_name_list=[f'{trainer.target}_score'])\n",
    "print(f'Mean score: {statistics.mean(score_list):.4f}')\n",
    "build_fold_result_df(fold_list=FOLD_LIST, score_list=score_list)\n",
    "# best_param_dict, score_list, _ = grid_search(\n",
    "#     train_model_fn=lambda params, fold: _VocabularyCatboostTrainer(params, plot=False)(fold),\n",
    "#     param_plan={\n",
    "#         'learning_rate': [None, 0.06, 0.065, 0.07, 0.075],\n",
    "#         'iterations': [None, 500, 1500],\n",
    "#     },\n",
    "#     fold_list=FOLD_LIST,\n",
    "#     print_best_params=True)\n",
    "# build_fold_result_df(fold_list=FOLD_LIST, score_list=score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('kaggle-fp-ell')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4646e3fde12bd3179c3551877f577659b7a8fa6d1b23b85720655ff3fa8cde14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
