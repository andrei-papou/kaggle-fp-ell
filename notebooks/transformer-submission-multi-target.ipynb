{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if 'KAGGLE_URL_BASE' in os.environ:\n",
    "    print('Running on Kaggle so initializing the environment...')\n",
    "\n",
    "    sys.path.append('/kaggle/input/kaggle-toolbox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from kaggle_toolbox.data import DatasetItem, Movable\n",
    "from kaggle_toolbox.device import CUDADevice\n",
    "from kaggle_toolbox.ensembling import EnsemblingStrategy, MeanEnsemblingStrategy\n",
    "from kaggle_toolbox.environment import Environment\n",
    "from kaggle_toolbox.nlp.transformer import Backbone, Model as TransformerModel, StandardModel, \\\n",
    "    MeanPooler, TakeNthSqueezer, get_tokenizer_for_backbone, \\\n",
    "    Tokenizer, TokenizerResult, TokenizerResultCollator, seed_everything\n",
    "from kaggle_toolbox.prediction import PredDict\n",
    "from kaggle_toolbox.predictor import StandardPredictor\n",
    "from kaggle_toolbox.progress import NotebookProgressBar\n",
    "from kaggle_toolbox.typing import DynamicDict\n",
    "from torch.utils.data import Dataset as TorchDataset, default_collate as default_collate_fn\n",
    "from transformers.data.data_collator import DataCollatorWithPadding\n",
    "from transformers.utils.generic import PaddingStrategy\n",
    "from transformers.utils.logging import set_verbosity_error as set_transformers_verbosity_error\n",
    "\n",
    "\n",
    "NotebookProgressBar.attach_to_pandas()\n",
    "set_transformers_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_X = t.TypeVar('_X', bound=Movable)\n",
    "\n",
    "class DatasetItemCollator(t.Generic[_X]):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            x_collate_fn: t.Callable[[t.List[_X]], _X],\n",
    "            id_collate_fn: t.Callable[[t.List[t.List[str]]], t.List[str]] = default_collate_fn):\n",
    "        self._x_collate_fn = x_collate_fn\n",
    "        self._id_collate_fn = id_collate_fn\n",
    "\n",
    "    def __call__(self, item_list: t.List[DatasetItem[_X]]) -> DatasetItem[_X]:\n",
    "        return DatasetItem(\n",
    "            id=self._id_collate_fn([item.id for item in item_list]),\n",
    "            x=self._x_collate_fn([item.x for item in item_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(TorchDataset[DatasetItem[TokenizerResult]]):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            df: pd.DataFrame,\n",
    "            tokenizer: Tokenizer,\n",
    "            max_len: int):\n",
    "        self._df = df.copy().reset_index(drop=True)\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "\n",
    "    def _get_tokenizer_input(self, row: DynamicDict) -> str:\n",
    "        (\n",
    "            full_text,\n",
    "         ) = (\n",
    "            row.get_typed_or_raise('full_text', str),\n",
    "         )\n",
    "\n",
    "        return full_text\n",
    "\n",
    "    def sort_by_tokenizer_input_len(self):\n",
    "        self._df['_tok_input_len'] = self._df.progress_apply(\n",
    "            lambda row: self._get_tokenizer_input(DynamicDict(t.cast(t.Dict[str, t.Any], row))), axis=1)\n",
    "        self._df = self._df.sort_values('_tok_input_len')\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> DatasetItem[TokenizerResult]:\n",
    "        row = self._df.iloc[idx]\n",
    "\n",
    "        tokenizer_input = self._get_tokenizer_input(DynamicDict(t.cast(t.Dict[str, t.Any], row)))\n",
    "        id = str(row['text_id'])\n",
    "\n",
    "        tokenizer_result = self._tokenizer.tokenize(\n",
    "            tokenizer_input, max_len=self._max_len)\n",
    "\n",
    "        return DatasetItem(\n",
    "            id=[id],\n",
    "            x=tokenizer_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENVIRONMENT = os.getenv('__KGLTBX_ENVIRONMENT', 'laptop')\n",
    "_env = _env = Environment(ENVIRONMENT)\n",
    "\n",
    "TARGET_LIST = [\n",
    "    'cohesion',\n",
    "    'syntax',\n",
    "    'vocabulary',\n",
    "    'phraseology',\n",
    "    'grammar',\n",
    "    'conventions',\n",
    "]\n",
    "\n",
    "SEED = 42\n",
    "NUM_FOLDS = 5\n",
    "DEVICE = CUDADevice()\n",
    "MAX_LEN = 1024\n",
    "BATCH_SIZE = _env.param(\n",
    "    kaggle=8,\n",
    "    # colab=4,\n",
    "    laptop=2)\n",
    "NUM_WORKERS = _env.param(kaggle=2, colab=2, laptop=4)\n",
    "\n",
    "ROOT_DIR = _env.param(\n",
    "    kaggle=Path('/kaggle'),\n",
    "    laptop=Path('/kaggle'))\n",
    "DATA_DIR = _env.param(\n",
    "    kaggle=ROOT_DIR / 'input',\n",
    "    laptop=ROOT_DIR / 'data')\n",
    "MODEL_DIR = _env.param(\n",
    "    kaggle=DATA_DIR,\n",
    "    laptop=ROOT_DIR / 'models')\n",
    "FP_ELL_DATASET_DIR = _env.param(\n",
    "    kaggle=DATA_DIR / 'feedback-prize-english-language-learning',\n",
    "    laptop=DATA_DIR / 'fp-ell')\n",
    "INPUT_CSV_PATH = _env.param(\n",
    "    kaggle=FP_ELL_DATASET_DIR / 'test.csv',\n",
    "    laptop=FP_ELL_DATASET_DIR / 'train.csv')\n",
    "OUTPUT_CSV_PATH = _env.param(\n",
    "    kaggle=ROOT_DIR / 'working/submission.csv',\n",
    "    laptop=ROOT_DIR / 'submission/submission.csv')\n",
    "\n",
    "BACKBONE = _env.param(\n",
    "    kaggle=str(DATA_DIR / 'deberta-v3-base'),\n",
    "    laptop='microsoft/deberta-v3-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'GPU model: {DEVICE.get_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pinning the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_data() -> pd.DataFrame:\n",
    "    return pd.read_csv(INPUT_CSV_PATH)\n",
    "\n",
    "all_df = _read_data()\n",
    "all_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_by_model(df: pd.DataFrame, model_builder: t.Callable[[], TransformerModel[TokenizerResult]]) -> PredDict:\n",
    "    tokenizer = get_tokenizer_for_backbone(backbone=BACKBONE, padding_strategy=PaddingStrategy.DO_NOT_PAD)\n",
    "    predictor = StandardPredictor(\n",
    "        model=model_builder(),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        collator=DatasetItemCollator(\n",
    "            id_collate_fn=lambda x: sum(x, []),\n",
    "            x_collate_fn=TokenizerResultCollator(DataCollatorWithPadding(tokenizer.tokenizer))),\n",
    "        device=DEVICE,\n",
    "        progress_bar=NotebookProgressBar())\n",
    "\n",
    "    dataset = Dataset(df, tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "    return predictor.predict(dataset)\n",
    "\n",
    "\n",
    "def _predict(\n",
    "        df: pd.DataFrame,\n",
    "        model_builder_list: t.List[t.Callable[[], TransformerModel[TokenizerResult]]],\n",
    "        ensembling_strategy: EnsemblingStrategy) -> PredDict:\n",
    "    return ensembling_strategy.ensemble([\n",
    "        _predict_by_model(df=df, model_builder=model_builder)\n",
    "        for model_builder in model_builder_list\n",
    "    ])\n",
    "\n",
    "\n",
    "def _build_multi_target_fold_model(fold: int) -> TransformerModel[TokenizerResult]:\n",
    "    backbone = Backbone.from_huggingface_checkpoint(BACKBONE, zero_out_dropout=True)\n",
    "    model = StandardModel(\n",
    "        backbone=backbone,\n",
    "        squeezer=TakeNthSqueezer(),\n",
    "        pooler=MeanPooler(),\n",
    "        dnn=torch.nn.Sequential(\n",
    "            torch.nn.LayerNorm(backbone.out_dim_size),\n",
    "            torch.nn.Linear(backbone.out_dim_size, len(TARGET_LIST)),\n",
    "        ))\n",
    "    model.load_state_dict(torch.load(\n",
    "        MODEL_DIR / f'fp-ell-transformer-training-multi-target/v1-layer_norm-5fold-fold_{fold}.pt'))\n",
    "    return model\n",
    "\n",
    "\n",
    "pred_df = pd.DataFrame([\n",
    "    {'id': id, **{target: score for target, score in zip(TARGET_LIST, score_list)}}\n",
    "    for id, score_list in _predict(\n",
    "        df=all_df,\n",
    "        model_builder_list=[\n",
    "            functools.partial(_build_multi_target_fold_model, fold=fold)\n",
    "            for fold in range(NUM_FOLDS)\n",
    "        ],\n",
    "        ensembling_strategy=MeanEnsemblingStrategy()).items()\n",
    "])\n",
    "pred_df.to_csv(OUTPUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('kaggle-fp-ell')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4646e3fde12bd3179c3551877f577659b7a8fa6d1b23b85720655ff3fa8cde14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
